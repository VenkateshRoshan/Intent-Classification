{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "import re\n",
    "import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "#from tensorflow.keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.callbacks import TensorBoard\n",
    "#import tensorflow\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "  df = pd.read_csv(filename, encoding = \"latin1\", names = [\"Sentence\", \"Intent\"])\n",
    "  print(df.head())\n",
    "  intent = df[\"Intent\"]\n",
    "  Intents = list(set(intent))\n",
    "  sentences = list(df[\"Sentence\"])\n",
    "  \n",
    "  return (intent, unique_intent, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Sentence          Intent\n",
      "0       Need help pleese  commonQ.assist\n",
      "1              Need help  commonQ.assist\n",
      "2       I need some info  commonQ.assist\n",
      "3      Will you help me?  commonQ.assist\n",
      "4  What else can you do?  commonQ.assist\n"
     ]
    }
   ],
   "source": [
    "intent, unique_intent, sentences = load_dataset(\"Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\venkey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venkey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentences):\n",
    "  words = []\n",
    "  for s in sentences:\n",
    "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
    "    w = word_tokenize(clean)\n",
    "    #stemming\n",
    "    words.append([i.lower() for i in w])\n",
    "    \n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1113"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "#print(cleaned_words)\n",
    "len(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "  token = Tokenizer(filters = filters)\n",
    "  token.fit_on_texts(words)\n",
    "  return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(words):\n",
    "  return(len(max(words, key = len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 492 and Maximum length = 28\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "  return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25,  77, 332,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 25,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,  25, 198, 181,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 51,  10,  77,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  8, 268,   4,  10,  30,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (1113, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faq.application_process': 1,\n",
       " 'commonq.not_giving': 2,\n",
       " 'commonq.query': 3,\n",
       " 'faq.address_proof': 4,\n",
       " 'commonq.name': 5,\n",
       " 'contact.contact': 6,\n",
       " 'faq.aadhaar_missing': 7,\n",
       " 'faq.bad_service': 8,\n",
       " 'faq.borrow_limit': 9,\n",
       " 'commonq.assist': 10,\n",
       " 'faq.biz_category_missing': 11,\n",
       " 'faq.approval_time': 12,\n",
       " 'commonq.how': 13,\n",
       " 'faq.biz_simpler': 14,\n",
       " 'commonq.bot': 15,\n",
       " 'commonq.wait': 16,\n",
       " 'faq.apply_register': 17,\n",
       " 'commonq.just_details': 18,\n",
       " 'faq.biz_new': 19,\n",
       " 'faq.banking_option_missing': 20,\n",
       " 'faq.borrow_use': 21}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1113, 1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(encode):\n",
    "  o = OneHotEncoder(sparse = False)\n",
    "  return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_one_hot = one_hot(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1113, 21)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (1001, 28) and train_Y = (1001, 21)\n",
      "Shape of val_X = (112, 28) and val_Y = (112, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
    "  model.add(Bidirectional(LSTM(128)))\n",
    "  model.add(Dense(50,activation='tanh'))\n",
    "  model.add(Dense(32, activation = \"relu\"))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Dense(21, activation = \"softmax\"))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 28, 128)           62976     \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 21)                693       \n",
      "=================================================================\n",
      "Total params: 341,319\n",
      "Trainable params: 278,343\n",
      "Non-trainable params: 62,976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, max_length)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1001 samples, validate on 112 samples\n",
      "Epoch 1/100\n",
      "1001/1001 [==============================] - 6s 6ms/step - loss: 2.9342 - acc: 0.0949 - val_loss: 2.8137 - val_acc: 0.1161\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.81365, saving model to Chat_Model.h5\n",
      "Epoch 2/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 2.7935 - acc: 0.1349 - val_loss: 2.6480 - val_acc: 0.1875\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.81365 to 2.64804, saving model to Chat_Model.h5\n",
      "Epoch 3/100\n",
      "1001/1001 [==============================] - 2s 2ms/step - loss: 2.6330 - acc: 0.1888 - val_loss: 2.4736 - val_acc: 0.2054\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.64804 to 2.47355, saving model to Chat_Model.h5\n",
      "Epoch 4/100\n",
      "1001/1001 [==============================] - 2s 2ms/step - loss: 2.5839 - acc: 0.2008 - val_loss: 2.4050 - val_acc: 0.2143\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.47355 to 2.40502, saving model to Chat_Model.h5\n",
      "Epoch 5/100\n",
      "1001/1001 [==============================] - 2s 2ms/step - loss: 2.4163 - acc: 0.2188 - val_loss: 2.2271 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.40502 to 2.22707, saving model to Chat_Model.h5\n",
      "Epoch 6/100\n",
      "1001/1001 [==============================] - 2s 2ms/step - loss: 2.1837 - acc: 0.2997 - val_loss: 1.9773 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.22707 to 1.97726, saving model to Chat_Model.h5\n",
      "Epoch 7/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 2.0064 - acc: 0.3596 - val_loss: 1.7733 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.97726 to 1.77332, saving model to Chat_Model.h5\n",
      "Epoch 8/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 1.8288 - acc: 0.4246 - val_loss: 1.6457 - val_acc: 0.4732\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.77332 to 1.64573, saving model to Chat_Model.h5\n",
      "Epoch 9/100\n",
      "1001/1001 [==============================] - 2s 2ms/step - loss: 1.6800 - acc: 0.4865 - val_loss: 1.5974 - val_acc: 0.4732\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.64573 to 1.59735, saving model to Chat_Model.h5\n",
      "Epoch 10/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 1.6293 - acc: 0.5045 - val_loss: 1.4711 - val_acc: 0.5804\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.59735 to 1.47114, saving model to Chat_Model.h5\n",
      "Epoch 11/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 1.4704 - acc: 0.5365 - val_loss: 1.3206 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.47114 to 1.32057, saving model to Chat_Model.h5\n",
      "Epoch 12/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 1.4053 - acc: 0.5664 - val_loss: 1.3143 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.32057 to 1.31429, saving model to Chat_Model.h5\n",
      "Epoch 13/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 1.2630 - acc: 0.6174 - val_loss: 1.2579 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.31429 to 1.25794, saving model to Chat_Model.h5\n",
      "Epoch 14/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 1.2956 - acc: 0.5864 - val_loss: 1.1228 - val_acc: 0.6339\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.25794 to 1.12284, saving model to Chat_Model.h5\n",
      "Epoch 15/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 1.1264 - acc: 0.6623 - val_loss: 1.0345 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.12284 to 1.03450, saving model to Chat_Model.h5\n",
      "Epoch 16/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 1.0609 - acc: 0.6783 - val_loss: 0.9649 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.03450 to 0.96494, saving model to Chat_Model.h5\n",
      "Epoch 17/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.9876 - acc: 0.7083 - val_loss: 0.9573 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.96494 to 0.95734, saving model to Chat_Model.h5\n",
      "Epoch 18/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.9132 - acc: 0.7353 - val_loss: 0.8879 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.95734 to 0.88790, saving model to Chat_Model.h5\n",
      "Epoch 19/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.8785 - acc: 0.7243 - val_loss: 0.7742 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.88790 to 0.77418, saving model to Chat_Model.h5\n",
      "Epoch 20/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.8615 - acc: 0.7363 - val_loss: 0.7919 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.77418\n",
      "Epoch 21/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.8253 - acc: 0.7512 - val_loss: 0.7810 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.77418\n",
      "Epoch 22/100\n",
      "1001/1001 [==============================] - 2s 2ms/step - loss: 0.7513 - acc: 0.7702 - val_loss: 0.6922 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.77418 to 0.69219, saving model to Chat_Model.h5\n",
      "Epoch 23/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.7279 - acc: 0.7842 - val_loss: 0.6630 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.69219 to 0.66299, saving model to Chat_Model.h5\n",
      "Epoch 24/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.6556 - acc: 0.8062 - val_loss: 0.6164 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.66299 to 0.61639, saving model to Chat_Model.h5\n",
      "Epoch 25/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.6755 - acc: 0.7852 - val_loss: 0.6404 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.61639\n",
      "Epoch 26/100\n",
      "1001/1001 [==============================] - ETA: 0s - loss: 0.8196 - acc: 0.730 - 3s 3ms/step - loss: 0.8167 - acc: 0.7323 - val_loss: 0.6443 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.61639\n",
      "Epoch 27/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.7097 - acc: 0.7792 - val_loss: 0.5924 - val_acc: 0.8304\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.61639 to 0.59241, saving model to Chat_Model.h5\n",
      "Epoch 28/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.5790 - acc: 0.8292 - val_loss: 0.5807 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.59241 to 0.58065, saving model to Chat_Model.h5\n",
      "Epoch 29/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.5589 - acc: 0.8312 - val_loss: 0.5904 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.58065\n",
      "Epoch 30/100\n",
      "1001/1001 [==============================] - 5s 5ms/step - loss: 0.5309 - acc: 0.8432 - val_loss: 0.5171 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.58065 to 0.51712, saving model to Chat_Model.h5\n",
      "Epoch 31/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.5437 - acc: 0.8292 - val_loss: 0.6532 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.51712\n",
      "Epoch 32/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.5076 - acc: 0.8372 - val_loss: 0.5153 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.51712 to 0.51526, saving model to Chat_Model.h5\n",
      "Epoch 33/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.4979 - acc: 0.8511 - val_loss: 0.5695 - val_acc: 0.8304\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.51526\n",
      "Epoch 34/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.4826 - acc: 0.8531 - val_loss: 0.5526 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.51526\n",
      "Epoch 35/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.4516 - acc: 0.8511 - val_loss: 0.5183 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.51526\n",
      "Epoch 36/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.4107 - acc: 0.8711 - val_loss: 0.4928 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.51526 to 0.49279, saving model to Chat_Model.h5\n",
      "Epoch 37/100\n",
      "1001/1001 [==============================] - 5s 5ms/step - loss: 0.3940 - acc: 0.8691 - val_loss: 0.4693 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.49279 to 0.46927, saving model to Chat_Model.h5\n",
      "Epoch 38/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3895 - acc: 0.8731 - val_loss: 0.4611 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.46927 to 0.46107, saving model to Chat_Model.h5\n",
      "Epoch 39/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3832 - acc: 0.8851 - val_loss: 0.4413 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.46107 to 0.44125, saving model to Chat_Model.h5\n",
      "Epoch 40/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.5274 - acc: 0.8432 - val_loss: 0.4949 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.44125\n",
      "Epoch 41/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3828 - acc: 0.8751 - val_loss: 0.4084 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.44125 to 0.40836, saving model to Chat_Model.h5\n",
      "Epoch 42/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3850 - acc: 0.8801 - val_loss: 0.4362 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.40836\n",
      "Epoch 43/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3154 - acc: 0.9081 - val_loss: 0.4409 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.40836\n",
      "Epoch 44/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.2799 - acc: 0.9191 - val_loss: 0.4245 - val_acc: 0.8839A: 0s - loss: 0.2757 - acc\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.40836\n",
      "Epoch 45/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.2905 - acc: 0.9111 - val_loss: 0.4217 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.40836\n",
      "Epoch 46/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3526 - acc: 0.8871 - val_loss: 0.4465 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.40836\n",
      "Epoch 47/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3112 - acc: 0.9051 - val_loss: 0.4239 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.40836\n",
      "Epoch 48/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.2912 - acc: 0.9061 - val_loss: 0.4626 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.40836\n",
      "Epoch 49/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3718 - acc: 0.8851 - val_loss: 0.4167 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.40836\n",
      "Epoch 50/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.2845 - acc: 0.9031 - val_loss: 0.4084 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.40836\n",
      "Epoch 51/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.2550 - acc: 0.9231 - val_loss: 0.3562 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.40836 to 0.35619, saving model to Chat_Model.h5\n",
      "Epoch 52/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.2438 - acc: 0.9211 - val_loss: 0.3729 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.35619\n",
      "Epoch 53/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.2260 - acc: 0.9271 - val_loss: 0.4092 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.35619\n",
      "Epoch 54/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1965 - acc: 0.9331 - val_loss: 0.3923 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.35619\n",
      "Epoch 55/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.2077 - acc: 0.9371 - val_loss: 0.4138 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.35619\n",
      "Epoch 56/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.2028 - acc: 0.9381 - val_loss: 0.3726 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.35619\n",
      "Epoch 57/100\n",
      "1001/1001 [==============================] - 5s 5ms/step - loss: 0.3305 - acc: 0.9101 - val_loss: 1.1165 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.35619\n",
      "Epoch 58/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3596 - acc: 0.8981 - val_loss: 0.4930 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.35619\n",
      "Epoch 59/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.2367 - acc: 0.9231 - val_loss: 0.4546 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.35619\n",
      "Epoch 60/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1918 - acc: 0.9471 - val_loss: 0.3922 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.35619\n",
      "Epoch 61/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1891 - acc: 0.9371 - val_loss: 0.4783 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.35619\n",
      "Epoch 62/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1778 - acc: 0.9491 - val_loss: 0.4214 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.35619\n",
      "Epoch 63/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.1798 - acc: 0.9371 - val_loss: 0.3793 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.35619\n",
      "Epoch 64/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1633 - acc: 0.9570 - val_loss: 0.3682 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.35619\n",
      "Epoch 65/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1621 - acc: 0.9461 - val_loss: 0.4203 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.35619\n",
      "Epoch 66/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1685 - acc: 0.9421 - val_loss: 0.4049 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.35619\n",
      "Epoch 67/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1673 - acc: 0.9471 - val_loss: 0.3993 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.35619\n",
      "Epoch 68/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1928 - acc: 0.9441 - val_loss: 0.8112 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.35619\n",
      "Epoch 69/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.2511 - acc: 0.9211 - val_loss: 0.3994 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.35619\n",
      "Epoch 70/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1579 - acc: 0.9411 - val_loss: 0.3861 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.35619\n",
      "Epoch 71/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1523 - acc: 0.9540 - val_loss: 0.4309 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.35619\n",
      "Epoch 72/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1514 - acc: 0.9471 - val_loss: 0.4607 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.35619\n",
      "Epoch 73/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1239 - acc: 0.9610 - val_loss: 0.4183 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.35619\n",
      "Epoch 74/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.4821 - acc: 0.8911 - val_loss: 0.7224 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.35619\n",
      "Epoch 75/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.3462 - acc: 0.8931 - val_loss: 0.4441 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.35619\n",
      "Epoch 76/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1975 - acc: 0.9481 - val_loss: 0.3846 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.35619\n",
      "Epoch 77/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1523 - acc: 0.9530 - val_loss: 0.4129 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.35619\n",
      "Epoch 78/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1366 - acc: 0.9610 - val_loss: 0.4459 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.35619\n",
      "Epoch 79/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1366 - acc: 0.9580 - val_loss: 0.4294 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.35619\n",
      "Epoch 80/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1269 - acc: 0.9540 - val_loss: 0.4059 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.35619\n",
      "Epoch 81/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1046 - acc: 0.9740 - val_loss: 0.4462 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.35619\n",
      "Epoch 82/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1035 - acc: 0.9660 - val_loss: 0.4345 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.35619\n",
      "Epoch 83/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1006 - acc: 0.9750 - val_loss: 0.4260 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.35619\n",
      "Epoch 84/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1039 - acc: 0.9660 - val_loss: 0.4624 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.35619\n",
      "Epoch 85/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1159 - acc: 0.9620 - val_loss: 0.4299 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.35619\n",
      "Epoch 86/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1112 - acc: 0.9590 - val_loss: 0.4090 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.35619\n",
      "Epoch 87/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1089 - acc: 0.9670 - val_loss: 0.4120 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.35619\n",
      "Epoch 88/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.1083 - acc: 0.9590 - val_loss: 0.4181 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.35619\n",
      "Epoch 89/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.0995 - acc: 0.9650 - val_loss: 0.4819 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.35619\n",
      "Epoch 90/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.1018 - acc: 0.9690 - val_loss: 0.4757 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.35619\n",
      "Epoch 91/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.1043 - acc: 0.9610 - val_loss: 0.4151 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.35619\n",
      "Epoch 92/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.0913 - acc: 0.9700 - val_loss: 0.4352 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.35619\n",
      "Epoch 93/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.0808 - acc: 0.9750 - val_loss: 0.3777 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.35619\n",
      "Epoch 94/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.0829 - acc: 0.9730 - val_loss: 0.4329 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.35619\n",
      "Epoch 95/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.0833 - acc: 0.9740 - val_loss: 0.4053 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.35619\n",
      "Epoch 96/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.0715 - acc: 0.9820 - val_loss: 0.4393 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.35619\n",
      "Epoch 97/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.0788 - acc: 0.9800 - val_loss: 0.4072 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.35619\n",
      "Epoch 98/100\n",
      "1001/1001 [==============================] - 3s 3ms/step - loss: 0.0657 - acc: 0.9850 - val_loss: 0.4484 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.35619\n",
      "Epoch 99/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.0746 - acc: 0.9750 - val_loss: 0.4579 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.35619\n",
      "Epoch 100/100\n",
      "1001/1001 [==============================] - 4s 4ms/step - loss: 0.0773 - acc: 0.9710 - val_loss: 0.4107 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.35619\n"
     ]
    }
   ],
   "source": [
    "filename = 'Chat_Model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "hist = model.fit(train_X, train_Y, epochs = 100, batch_size = 32, validation_data = (val_X, val_Y), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Chat_Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading ChatBot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"Chat_Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting The result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "  clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "  test_word = word_tokenize(clean)\n",
    "  test_word = [w.lower() for w in test_word]\n",
    "  test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "  print(test_word)\n",
    "  #Check for unknown words\n",
    "  if [] in test_ls:\n",
    "    test_ls = list(filter(None, test_ls))\n",
    "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    "  x = padding_doc(test_ls, max_length)\n",
    "  pred = model.predict_proba(x)\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_output(pred, classes):\n",
    "  predictions = pred[0]\n",
    " \n",
    "  classes = np.array(classes)\n",
    "  ids = np.argsort(-predictions)\n",
    "  classes = classes[ids]\n",
    "  predictions = -np.sort(-predictions)\n",
    " \n",
    "  #for i in range(pred.shape[1]):\n",
    "    #print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "    \n",
    "  #print(predictions[0])\n",
    "  return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " why are you here?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['why', 'are', 'you', 'here']\n",
      "commonQ.bot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "text = input()\n",
    "pred = predictions(text)\n",
    "res = get_final_output(pred, unique_intent)\n",
    "plt.scatter(pred,Intents)\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faq.application_process',\n",
       " 'commonq.not_giving',\n",
       " 'commonq.query',\n",
       " 'faq.address_proof',\n",
       " 'commonq.name',\n",
       " 'contact.contact',\n",
       " 'faq.aadhaar_missing',\n",
       " 'faq.bad_service',\n",
       " 'faq.borrow_limit',\n",
       " 'commonq.assist',\n",
       " 'faq.biz_category_missing',\n",
       " 'faq.approval_time',\n",
       " 'commonq.how',\n",
       " 'faq.biz_simpler',\n",
       " 'commonq.bot',\n",
       " 'commonq.wait',\n",
       " 'faq.apply_register',\n",
       " 'commonq.just_details',\n",
       " 'faq.biz_new',\n",
       " 'faq.banking_option_missing',\n",
       " 'faq.borrow_use']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
